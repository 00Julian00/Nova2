"""
Description: Provides abstract classes for all custom datatypes.
"""

from abc import ABC, abstractmethod
from typing import Literal

from numpy import ndarray
from torch import Tensor

class AudioDataBase(ABC):
    """
    Stores wave and mp3 audio data.
    """

class MessageBase(ABC):
    """
    Stores one message in a conversation.

    Arguments:
        author (str): The author of the message.
        content (str): The content of the message.
    """
    pass

class ConversationBase(ABC):
    """
    Stores the conversation between the LLM and the user.
    """
    @abstractmethod
    def add_message(self, message: MessageBase) -> None:
        """
        Add one message to the conversation.

        Arguments:
            message (Message): The message that will be added.
        """
        raise NotImplementedError
    @abstractmethod
    def add_messages(self, messages: list[MessageBase]) -> None:
        """
        Add multiple messages to the conversation.

        Arguments:
            messages (list[Message]): The messages that will be added.
        """
        raise NotImplementedError
    @abstractmethod
    def delete_newest(self, author: Literal["user", "assistant", "system", None] = None) -> None:
        """
        Delete the newest message in the conversation. If an author is parsed, the newest message with that author is deleted.

        Arguments:
            author (Literal["user", "assistant", "system", None]): An optional parameter. The author whose newest message will be deleted.
        """
        raise NotImplementedError
    @abstractmethod
    def delete_all_from(self, author: Literal["user", "assistant", "system"]) -> None:
        """
        Delete all messages from an author. Can be used to purge system prompts if behavior should be overwritten.

        Arguments:
            author (Literal["user", "assistant", "system"]): The author from whom all messages should be deleted.
        """
        raise NotImplementedError
    @abstractmethod
    def get_newest(self, author: Literal["user", "assistant", "system", None] = None) -> MessageBase | None:
        """
        Get the newest message. If an author is parsed, the newest message of that author will be returned.

        Arguments:
            author (Literal["user", "assistant", "system", None]): An optional parameter. The author whose newest message will be returned.

        Returns:
            Message | None: The newest message (from the author). None if there are no messages in the conversation or no messages from the specified author.
        """
        raise NotImplementedError
    @abstractmethod
    def to_list(self) -> list[dict]:
        """
        Convert the stored conversation to a format that can be parsed to the LLM.

        Returns:
            list[dict]: The formatted conversation.
        """
        raise NotImplementedError
    @abstractmethod
    def from_list(self, conversation: list[dict]) -> None:
        """
        Convert the LLM format conversation into a conversation object. Overwrites the stored conversation.

        Arguments:
            conversation (list[dict]): The conversation that should be converted and stored.
        """
        raise NotImplementedError

class ContextSourceBase(ABC):
    """
    Base class for all context sources.
    """
    @classmethod
    @abstractmethod
    def get_all_sources(cls) -> list[type]:
        """
        Returns a list of all subclasses of this class.
        """
        raise NotImplementedError
        
class ContextSource_VoiceABC(ContextSourceBase):
    """
    Context source for results generated by the transcriptor.
    """
    pass

class ContextSource_UserABC(ContextSourceBase):
    """
    Context source for direct user input.
    """
    pass

class ContextSource_AssistantABC(ContextSourceBase):
    """
    Context source for responses generated by the assistant.
    """
    pass

class ContextSource_ToolResponseABC(ContextSourceBase):
    """
    Context source for responses generated by tools.
    """
    pass

class ContextSource_SystemABC(ContextSourceBase):
    """
    Context source for system messages.
    """
    pass

class ContextDatapointBase(ABC):
    """
    This class holds a singular datapoint in the context.
    """
    @abstractmethod
    def to_dict(self) -> dict:
        """
        Returns the contents formatted to a dictionary so it can be serialized to json.
        """
        raise NotImplementedError

class ContextBase(ABC):
    """
    This class stores context which is a list of datapoints all with source, content and timestamp.
    """
    @abstractmethod
    def to_conversation(self) -> ConversationBase:
        """
        Get the context as type Conversation that can be parsed to the LLM.
        """
        raise NotImplementedError

class ContextGeneratorBase(ABC):
    """
    Holds the data generator produced by a context generator. Yields ContextDatapoint.
    """
    @abstractmethod
    def data(self):
        """
        Begins to yield the data generated by the generator.
        """
        raise NotImplementedError

class ContextGeneratorListBase(ABC):
    """
    Manages a dynamic thread-safe list of context sources that can be iterated through.
    """
    @abstractmethod
    def add(self, context_source: ContextGeneratorBase) -> None:
        """
        Adds a context source to the list.
        """
        raise NotImplementedError
    @abstractmethod
    def remove(self, context_source: ContextGeneratorBase) -> None:
        """
        Removes a context source from the list.
        """
        raise NotImplementedError
    @abstractmethod
    def get_next(self) -> ContextDatapointBase:
        """
        Gets the next context datapoint from the list.
        """
        raise NotImplementedError

class MemoryConfigBase(ABC):
    """
    Stores the settings that determines how memories are retrieved.

    Arguments:
        retrieve_memories (bool): Whether to search for memories in the database.
        num_results (int): The maximum amount of results that should be fed to the model.
        search_area (int): How much context around the search result should additionally be fed to the model.
        cosine_threshold (float): The similarity threshold a result must surpass to be utilized.
    """
    pass

class LLMResponseBase(ABC):
    """
    Stores the response of the LLM.
    """
    message: str = ""
    @abstractmethod
    def from_dict(self, llm_response: dict) -> None:
        """
        Constructs the LLMResponse object including tool calls from the LLM response.

        Arguments:
            llm_response (dict): The response from the LLM that will be converted.
        """
        raise NotImplementedError
    @abstractmethod
    def to_message(self) -> MessageBase:
        """
        Formats the LLM reponse to a Message object.
        """
        raise NotImplementedError

class LLMToolParameterBase(ABC):
    """
    Defines a parameter for a tool.

    Arguments:
        name (str): The name of the parameter. Should be short and accurate.
        description (str): A description in natural language. Helps the LLM to understand how to use the parameter.
        type (str): What datatype the parameter is, i.e. bool, int, string etc.
        required (bool): Whether the parameter has to be parsed.
    """
    pass

class LLMToolBase(ABC):
    """
    Defines a tool that can be used by the LLM.

    Arguments:
        name (str): The name of the tool. Should be short and accurate.
        description (str): A description in natural language. Helps the LLM to understand how to use the tool.
        parameters (List[LLMToolParameter]): A list of parameters the tool can take.
    """
    @abstractmethod
    def to_dict(self) -> dict:
        """
        Converts a list of LLMTools to the proper json format for the LLM and returns it as a dictionary.
        """
        raise NotImplementedError

class LoadedToolBase(ABC):
    """
    Defines a loaded tool that can be executed
    """
    pass

class LLMToolCallParameterBase(ABC):
    """
    Defines a parameter for a tool call.
    """
    pass

class LLMToolCallBase(ABC):
    """
    Defines a tool call made by the LLM.
    """
    pass

class WordBase(ABC):
    """
    A class to represent a word in a transcription.

    This class holds a singular word from a transcription, together with other relevant information.

    Arguments:
        text (str, optional): The text of the word. Defaults to "".
        start (float, optional): The start time of the word in seconds. Defaults to 0.
        end (float, optional): The end time of the word in seconds. Defaults to 0.
        speaker_embedding (torch.FloatTensor, optional): The speaker embedding of the voice that said the word. Defaults to None.
    """
    pass

class STTConditioningBase(ABC):
    """
    Stores all values required for transcriptor conditioning.

    Arguments:
        model (str): The model to use.
        microphone_index (int): The index of the microphone to use for recording.
        device (str): The device to use for the computations. Defaults to "cuda" or "cpu" if cuda is not available.
        voice_boost (float): How much to boost the voice in the audio preprocessing stage. Setting it to 0 disables this feature. Defaults to 10.0.
        vad_threshold (float): The confidence threshold of the voice-activity-detection model. Audio chunks above this threshold will be considered to contain speech.
        voice_similarity_threshold (float): The threshold for the voice similarity. If the similarity between the speaker and a voice in the database, they will be considered to be the same voice. Defaults to 0.8.
    """
    pass

class STTInferenceEngineBase(ABC):
    """
    Provides a base class for all STT inference engines to ensure a consistent structure.
    """
    @abstractmethod
    def initialize_model(self, conditioning: STTConditioningBase) -> None:
        """
        Load the model into VRAM/RAM. Required to run inference. Call free() to free up the VRAM/RAM again.
        """
        raise NotImplementedError
    @abstractmethod
    def free(self) -> None:
        """
        Frees the VRAM/RAM. The model can not be used anymore after it was freed. It needs to be loaded again by calling select_model().
        """
        raise NotImplementedError
    @abstractmethod
    def run_inference(self, audio_data: ndarray | Tensor, language: str = "") -> list[WordBase]:
        """
        Transcribe audio data into a word array.

        Arguments:
            audio_data (ndarray | Tensor): The audio data to transcribe as a numpy array or a torch tensor.
            language (str): What language the speech is in. Results in better transcriptions if set correctly. Leave as an empty string if the speech is in multiple languages or the language is unknown. Defaults to "".

        Returns:
            LLMResponse: The response from the LLM.
        """
        raise NotImplementedError

class LLMConditioningBase(ABC):
    """
    Stores all values required for LLM conditioning.

    Arguments:
        model (str): The model name. Must a valid huggingface repo ID.
        file (str): The file to use from that repo. Must be GGUF format.
        inference_engine (str): The inference engine to use.
        filter_thinking_process (bool): Wether to automatically remove the "thinking" part of an LLM response (essentially only using the response after the </think> token).
        temperature (float): The temperature to use for inference.
        max_completion_tokens (int): How many tokens the model is allowed to generate.
        add_default_sys_prompt (bool): Should an extra system prompt be added to the LLM that adds context about the Nova system?
    """
    pass

class LLMInferenceEngineBase(ABC):
    """
    Provides a base class for all LLM inference engines to ensure a consistent structure.
    """
    @abstractmethod
    def initialize_model(self, conditioning: LLMConditioningBase) -> None:
        """
        Load the model into VRAM/RAM. Required to run inference. Call free() to free up the VRAM/RAM again.
        """
        raise NotImplementedError
    @abstractmethod
    def free(self) -> None:
        """
        Frees the VRAM/RAM. The model can not be used anymore after it was freed. It needs to be loaded again by calling select_model().
        """
        raise NotImplementedError
    @abstractmethod
    def run_inference(self, conversation: ConversationBase, tools: list[LLMToolBase] | None) -> LLMResponseBase:
        """
        Prompt the LLM and get an answer from it.

        Arguments:
            conversation (Conversation): The conversation to use.
            tools (list[LLMTool]): A list of tools the LLM can access.

        Returns:
            LLMResponse: The response from the LLM.
        """
        raise NotImplementedError

class TTSConditioningBase(ABC):
    """
    Stores all values required for TTS conditioning.
    Note that some parameters are inference engine exclusive and will be ignored if an incompatible engine is used.

    Arguments:
        model (str): The TTS model to use. Must be a valid huggingface repo ID.
        voice (str): The voice to use. Must be a valid voice name.
        expressivness (float): The expressiveness of the voice. 0 is neutral, 1 is very expressive.
        stability (float): The stability of the voice. 0 is very unstable, 1 is very stable.
    """
    pass

class TTSInferenceEngineBase(ABC):
    """
    Provides a base class for all TTS inference engines to ensure a consistent structure.
    """
    @abstractmethod
    def initialize_model(self, model) -> None:
        """
        Load the model into VRAM/RAM. Required to run inference. Call free() to free up the VRAM/RAM again.
        """
        raise NotImplementedError
    @abstractmethod
    def free(self) -> None:
        """
        Frees the VRAM/RAM. The model can not be used anymore after it was freed. It needs to be loaded again by calling select_model().
        """
        raise NotImplementedError
    @abstractmethod
    def run_inference(self, text: str, conditioning: TTSConditioningBase, stream: bool) -> AudioDataBase:
        """
        Get the spoken text from the TTS.

        Arguments:
            text (str): The text to convert to speech.
            conditioning (TTSConditioning): The conditioning to use for the TTS.
            stream (bool): Whether to stream the audio or not.

        Returns:
            bytes: The audio data.
        """
        raise NotImplementedError
    
    @abstractmethod
    def clone_voice(self, audio_dir: str, name: str) -> None:
        """
        Create a new voice embedding from a recording.

        Arguments:
            audio_dir (str): The directory of the audio file containing the voice.
            name (str): The name under which the voice should be saved.
        """
        raise NotImplementedError